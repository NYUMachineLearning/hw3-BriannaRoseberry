trainSize <- floor(0.75 * nrow(BreastCancer))
set.seed(543)
trainPos <- sample(seq_len(nrow(BreastCancer)), size = trainSize)
trainClassifier <- BreastCancer[trainPos,]
testClassifier <- BreastCancer[-trainPos,]
dim(trainClassifier)
dim(testClassifier)
csize <- ggplot(data = BreastCancer, aes(x = Cell.size, fill = Class)) +
geom_histogram(position="identity", alpha=0.5, bins= 25)  +
theme_bw()
swidth <- ggplot(data = BreastCancer, aes(x = Sepal.Width, fill = Class)) +
geom_histogram(position="identity", alpha=0.5, bins= 25) +
theme_bw()
plength <- ggplot(data = BreastCancer, aes(x = Petal.Length, fill = Class)) +
geom_histogram(position="identity", alpha=0.5, bins= 25) +
theme_bw()
pwidth <- ggplot(data = BreastCancer, aes(x = Petal.Width, fill = Class)) +
geom_histogram(position="identity", alpha=0.5, bins= 25) +
theme_bw()
grid.arrange(slength, swidth, plength, pwidth)
library(mlbench)
data(BreastCancer)
BreastCancer <- na.omit(BreastCancer)
summary(BreastCancer)
trainSize <- floor(0.75 * nrow(BreastCancer))
set.seed(543)
trainPos <- sample(seq_len(nrow(BreastCancer)), size = trainSize)
trainClassifier <- BreastCancer[trainPos,]
testClassifier <- BreastCancer[-trainPos,]
dim(trainClassifier)
dim(testClassifier)
csize <- ggplot(data = BreastCancer, aes(x = Cell.size, fill = Class)) +
geom_histogram(position="identity", alpha=0.5, bins= 25)  +
theme_bw()
library(caret)
library(ROCR)
library(pROC)
library(MASS)
library(ggplot2)
library(gridExtra)
library(dplyr)
library(ggfortify)
library(glmnet)
library(tidyverse)
train_size <- floor(0.75 * nrow(airquality))
set.seed(543)
train_pos <- sample(seq_len(nrow(airquality)), size = train_size)
train_regression <- airquality[train_pos,-c(1,2)]
test_regression <- airquality[-train_pos,-c(1,2)]
dim(train_regression)
dim(test_regression)
?trainControl
ctrl =  trainControl(method = "boot", 15)
Ridge_regression <- train(Temp ~ Wind + Month, data = train_regression,
method = 'ridge', trControl= ctrl)
Ridge_regression
ridge_test_pred <- predict(Ridge_regression, newdata = test_regression)
#plot the predicted values vs the observed values
plot_ridge_test_pred <- data.frame(Temp_test_pred = ridge_test_pred,
Observed_Temp = test_regression$Temp)
ggplot(data = plot_ridge_test_pred) +
geom_point(aes(x=Observed_Temp, y = Temp_test_pred)) +
ggtitle("True Temp Value vs Predicted Temp Value Ridge Regression") +
theme_bw()
#median residual value should be close to zero
median(resid(Ridge_regression))
ctrl =  trainControl(method = "boot", 15)
lasso_regression <- train(Temp ~ Wind + Month, data = train_regression,
method = 'lasso', trControl= ctrl)
lasso_regression
lasso_test_pred <- predict(lasso_regression, newdata = test_regression)
#plot the predicted values vs the observed values
plot_lasso_test_pred <- data.frame(Temp_test_pred = lasso_test_pred,
Observed_Temp = test_regression$Temp)
ggplot(data = plot_lasso_test_pred) +
geom_point(aes(x=Observed_Temp, y = Temp_test_pred)) +
ggtitle("True Temp Value vs Predicted Temp Value Lasso Regression") +
theme_bw()
#median residual value should be close to zero
median(resid(lasso_regression))
data(iris)
#split into training and test set
train_size <- floor(0.75 * nrow(iris))
set.seed(543)
train_pos <- sample(seq_len(nrow(iris)), size = train_size)
train_classifier <- iris[train_pos,]
test_classifier <- iris[-train_pos,]
dim(train_classifier)
dim(test_classifier)
slength <- ggplot(data = iris, aes(x = Sepal.Length, fill = Species)) +
geom_histogram(position="identity", alpha=0.5, bins= 25)  +
theme_bw()
swidth <- ggplot(data = iris, aes(x = Sepal.Width, fill = Species)) +
geom_histogram(position="identity", alpha=0.5, bins= 25) +
theme_bw()
plength <- ggplot(data = iris, aes(x = Petal.Length, fill = Species)) +
geom_histogram(position="identity", alpha=0.5, bins= 25) +
theme_bw()
pwidth <- ggplot(data = iris, aes(x = Petal.Width, fill = Species)) +
geom_histogram(position="identity", alpha=0.5, bins= 25) +
theme_bw()
grid.arrange(slength, swidth, plength, pwidth)
LDA <- lda(Species~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,
data= train_classifier, cv= T)
LDA
#predict the species of the test data
LDA_predict <- predict(LDA, newdata=test_classifier)
confusionMatrix(LDA_predict$class, reference = test_classifier$Species)
# save the predictions in a new variable
predictions <- as.data.frame(LDA_predict$posterior) %>%
rownames_to_column("idx")
test_classifier <- test_classifier %>%
rownames_to_column("idx")
predictions_actual <- full_join(predictions,test_classifier, by = "idx" )
# choose the two classes we want to compare, setosa and versicolor
set_vers_true_labels <- predictions_actual %>%
filter(Species %in% c("setosa", "versicolor")) %>%
mutate(Species = as.character(Species))
#make dataframe of the prediction and the label
pred_label <- data.frame(prediction = set_vers_true_labels$setosa,
label = set_vers_true_labels$Species)
ggplot(pred_label, aes(x = 1:24, y = prediction, color = label))+
geom_point()
pred <- prediction(set_vers_true_labels$setosa, set_vers_true_labels$Species,
label.ordering = c("versicolor", "setosa"))
perf <- performance(pred,"tpr","fpr")
plot(perf)
data(iris)
#split into training and test set
train_size <- floor(0.75 * nrow(iris))
set.seed(543)
train_pos <- sample(seq_len(nrow(iris)), size = train_size)
train_classifier <- iris[train_pos,]
test_classifier <- iris[-train_pos,]
dim(train_classifier)
dim(test_classifier)
#only look at two classes
train_classifier_log <- train_classifier[c(which(train_classifier$Species == "setosa"),
which(train_classifier$Species == "versicolor")),]
test_classifier_log <- test_classifier[c(which(test_classifier$Species == "setosa"),
which(test_classifier$Species == "versicolor")),]
train_classifier_log$Species <- factor(train_classifier_log$Species)
test_classifier_log$Species <- factor(test_classifier_log$Species)
ctrl <- trainControl(method = "repeatedcv", repeats = 15,classProbs = T,
savePredictions = T)
#create model. logistic regression is a bionomial general linear model.
#predict species based on sepal length
logistic_regression <- train(Species~ Sepal.Length, data = train_classifier_log,
method = "glm", family= "binomial", trControl = ctrl)
logistic_regression
summary(logistic_regression)
plot(x = roc(predictor = logistic_regression$pred$setosa,
response = logistic_regression$pred$obs)$specificities,
y = roc(predictor = logistic_regression$pred$setosa,
response = logistic_regression$pred$obs)$sensitivities,
col= "blue", xlim = c(1, 0), type ="l", ylab = "Sensitivity",
xlab = "Specificity")
legend("bottomright", legend = paste("setosa v versicolor --",
roc(predictor = logistic_regression$pred$setosa,
response = logistic_regression$pred$obs)$auc
, sep = ""), col = c("blue"), fill = c("blue"))
#predict iris species using Sepal legth
logistic_regression_predict_class <- predict(logistic_regression,
newdata = test_classifier_log)
#confusion matrix
confusionMatrix(logistic_regression_predict_class,
reference = test_classifier_log$Species)
logistic_regression_predict <- predict(logistic_regression,
newdata = test_classifier_log, type = "prob")
# To convert from a probability to odds, divide the probability by one minus that probability. So if the probability is 10% or 0.10 , then the odds are 0.1/0.9 or ‘1 to 9’
odds_species1 <- logistic_regression_predict[,1] / (1 - logistic_regression_predict[,1])
log_odds_species1 <- log(odds_species1)
cor.test(log_odds_species1, test_classifier_log$Sepal.Length)
plot(log_odds_species1, test_classifier_log$Sepal.Length)
logistic_predict_prob <- predict(logistic_regression,
newdata = test_classifier_log, type="prob")
logistic_pred_prob_plot <- data.frame(Species_pred = logistic_predict_prob, Sepal.Length  = test_classifier_log$Sepal.Length)
test_classifier_log$Species <- as.numeric(test_classifier_log$Species) -1
ggplot(data = test_classifier_log) +
geom_point(aes(x=Sepal.Length, y = Species)) +
geom_line(data = logistic_pred_prob_plot, aes(x = Sepal.Length,
y = Species_pred.setosa, col =  "setosa"))+
geom_line(data = logistic_pred_prob_plot, aes(x = Sepal.Length,
y = Species_pred.versicolor, col = "versicolor"))+
ggtitle("Probabilities for classifying species")
library(mlbench)
data(BreastCancer)
BreastCancer <- na.omit(BreastCancer)
summary(BreastCancer)
trainSize <- floor(0.75 * nrow(BreastCancer))
set.seed(543)
trainPos <- sample(seq_len(nrow(BreastCancer)), size = trainSize)
trainClassifier <- BreastCancer[trainPos,]
testClassifier <- BreastCancer[-trainPos,]
dim(trainClassifier)
dim(testClassifier)
csize <- ggplot(data = BreastCancer, aes(x = Cell.size, fill = Class)) +
geom_histogram(position="identity", alpha=0.5, bins= 25)  +
theme_bw()
swidth <- ggplot(data = BreastCancer, aes(x = Sepal.Width, fill = Class)) +
geom_histogram(position="identity", alpha=0.5, bins= 25) +
theme_bw()
plength <- ggplot(data = BreastCancer, aes(x = Petal.Length, fill = Class)) +
geom_histogram(position="identity", alpha=0.5, bins= 25) +
theme_bw()
pwidth <- ggplot(data = BreastCancer, aes(x = Petal.Width, fill = Class)) +
geom_histogram(position="identity", alpha=0.5, bins= 25) +
theme_bw()
grid.arrange(slength, swidth, plength, pwidth)
library(mlbench)
data(BreastCancer)
BreastCancer <- na.omit(BreastCancer)
BreastCancer
trainSize <- floor(0.75 * nrow(BreastCancer))
set.seed(543)
trainPos <- sample(seq_len(nrow(BreastCancer)), size = trainSize)
trainClassifier <- BreastCancer[trainPos,]
testClassifier <- BreastCancer[-trainPos,]
dim(trainClassifier)
dim(testClassifier)
csize <- ggplot(data = BreastCancer, aes(x = Cell.size, fill = Class)) +
geom_histogram(position="identity", alpha=0.5, bins= 25)  +
theme_bw()
swidth <- ggplot(data = BreastCancer, aes(x = Sepal.Width, fill = Class)) +
geom_histogram(position="identity", alpha=0.5, bins= 25) +
theme_bw()
plength <- ggplot(data = BreastCancer, aes(x = Petal.Length, fill = Class)) +
geom_histogram(position="identity", alpha=0.5, bins= 25) +
theme_bw()
pwidth <- ggplot(data = BreastCancer, aes(x = Petal.Width, fill = Class)) +
geom_histogram(position="identity", alpha=0.5, bins= 25) +
theme_bw()
grid.arrange(slength, swidth, plength, pwidth)
library(mlbench)
data(BreastCancer)
BreastCancer <- na.omit(BreastCancer)
BreastCancer
trainSize <- floor(0.75 * nrow(BreastCancer))
set.seed(543)
trainPos <- sample(seq_len(nrow(BreastCancer)), size = trainSize)
trainClassifier <- BreastCancer[trainPos,]
testClassifier <- BreastCancer[-trainPos,]
dim(trainClassifier)
dim(testClassifier)
cthick <- ggplot(data = BreastCancer, aes(x = Cl.thickness, fill = Class)) +
geom_histogram(position="identity", alpha=0.5, bins= 25)  +
theme_bw()
csize <- ggplot(data = BreastCancer, aes(x = Cell.Size, fill = Class)) +
geom_histogram(position="identity", alpha=0.5, bins= 25) +
theme_bw()
cshape <- ggplot(data = BreastCancer, aes(x = Cell.shape, fill = Class)) +
geom_histogram(position="identity", alpha=0.5, bins= 25) +
theme_bw()
adh <- ggplot(data = BreastCancer, aes(x = Marg.adhesion, fill = Class)) +
geom_histogram(position="identity", alpha=0.5, bins= 25) +
theme_bw()
grid.arrange(cthick, csize, cshape, adh)
library(mlbench)
data(BreastCancer)
BreastCancer <- na.omit(BreastCancer)
BreastCancer
trainSize <- floor(0.75 * nrow(BreastCancer))
set.seed(543)
trainPos <- sample(seq_len(nrow(BreastCancer)), size = trainSize)
trainClassifier <- BreastCancer[trainPos,]
testClassifier <- BreastCancer[-trainPos,]
dim(trainClassifier)
dim(testClassifier)
cthick <- ggplot(data = BreastCancer, aes(x = Cl.thickness, fill = Class)) +
geom_histogram(position="identity", alpha=0.5, bins= 25)  +
theme_bw()
csize <- ggplot(data = BreastCancer, aes(x = Cell.Size, fill = Class)) +
geom_histogram(position="identity", alpha=0.5, bins= 25) +
theme_bw()
cshape <- ggplot(data = BreastCancer, aes(x = Cell.shape, fill = Class)) +
geom_histogram(position="identity", alpha=0.5, bins= 25) +
theme_bw()
adh <- ggplot(data = BreastCancer, aes(x = Marg.adhesion, fill = Class)) +
geom_histogram(position="identity", alpha=0.5, bins= 25) +
theme_bw()
#train
#test
##ctrl <- trainControl()
## <- train(, data = , method = "", trControl = ctrl)
## predict(, newdata="")
library(mlbench)
data(BreastCancer)
BreastCancer <- na.omit(BreastCancer)
BreastCancer
trainSize <- floor(0.75 * nrow(BreastCancer))
set.seed(543)
trainPos <- sample(seq_len(nrow(BreastCancer)), size = trainSize)
trainClassifier <- BreastCancer[trainPos,]
testClassifier <- BreastCancer[-trainPos,]
dim(trainClassifier)
dim(testClassifier)
cthick <- ggplot(data = BreastCancer, aes(x = Cl.thickness, fill = Class)) +
geom_histogram(position="identity", alpha=0.5, bins= 25)  +
theme_bw()
csize <- ggplot(data = BreastCancer, aes(x = Cell.Size, fill = Class)) +
geom_histogram(position="identity", alpha=0.5, bins= 25) +
theme_bw()
cshape <- ggplot(data = BreastCancer, aes(x = Cell.shape, fill = Class)) +
geom_histogram(position="identity", alpha=0.5, bins= 25) +
theme_bw()
adh <- ggplot(data = BreastCancer, aes(x = Marg.adhesion, fill = Class)) +
geom_histogram(position="identity", alpha=0.5, bins= 25) +
theme_bw()
cthick
library(mlbench)
data(BreastCancer)
BreastCancer <- na.omit(BreastCancer)
trainSize <- floor(0.75 * nrow(BreastCancer))
set.seed(543)
trainPos <- sample(seq_len(nrow(BreastCancer)), size = trainSize)
trainClassifier <- BreastCancer[trainPos,]
testClassifier <- BreastCancer[-trainPos,]
dim(trainClassifier)
dim(testClassifier)
##ctrl <- trainControl()
## <- train(, data = , method = "", trControl = ctrl)
## predict(, newdata="")
train_classifier_log <- train_classifier[c(which(train_classifier$Class= "Benign"),
train_classifier_log <- train_classifier[c(which(train_classifier$Class== "Benign"),
which(train_classifier$Class == "versicolor")),]
test_classifier_log <- test_classifier[c(which(test_classifier$Class == "Benign"),
which(test_classifier$Class == "versicolor")),]
train_classifier_log$Class <- factor(train_classifier_log$Class)
test_classifier_log$Class <- factor(test_classifier_log$Class)
ctrl <- trainControl(method = "repeatedcv", repeats = 15,classProbs = T,
savePredictions = T)
#create model. logistic regression is a bionomial general linear model.
#predict species based on sepal length
logistic_regression <- train(Class~ Cell.size, data = train_classifier_log,
method = "glm", family= "binomial", trControl = ctrl)
library(mlbench)
data(BreastCancer)
BreastCancer <- na.omit(BreastCancer)
BreastCancer
trainSize <- floor(0.75 * nrow(BreastCancer))
set.seed(543)
trainPos <- sample(seq_len(nrow(BreastCancer)), size = trainSize)
trainClassifier <- BreastCancer[trainPos,]
testClassifier <- BreastCancer[-trainPos,]
dim(trainClassifier)
dim(testClassifier)
train_classifier_log <- train_classifier[c(which(train_classifier$Class== "Benign"),
which(train_classifier$Class == "versicolor")),]
test_classifier_log <- test_classifier[c(which(test_classifier$Class == "Benign"),
which(test_classifier$Class == "versicolor")),]
train_classifier_log$Class <- factor(train_classifier_log$Class)
test_classifier_log$Class <- factor(test_classifier_log$Class)
ctrl <- trainControl(method = "repeatedcv", repeats = 15,classProbs = T,
savePredictions = T)
#create model. logistic regression is a bionomial general linear model.
#predict species based on sepal length
logistic_regression <- train(Class~ Cell.size, data = train_classifier_log,
method = "glm", family= "binomial", trControl = ctrl)
train_classifier_log <- trainClassifier[c(which(trainClassifier$Class== "Benign"),
which(trainClassifier$Class == "versicolor")),]
test_classifier_log <- testClassifier[c(which(testClassifier$Class == "Benign"),
which(testClassifier$Class == "versicolor")),]
train_classifier_log$Class <- factor(train_classifier_log$Class)
test_classifier_log$Class <- factor(test_classifier_log$Class)
ctrl <- trainControl(method = "repeatedcv", repeats = 15,classProbs = T,
savePredictions = T)
#create model. logistic regression is a bionomial general linear model.
#predict species based on sepal length
logistic_regression <- train(Class~ Cell.size, data = train_classifier_log,
method = "glm", family= "binomial", trControl = ctrl)
trainClassifierLog <- trainClassifier[c(which(trainClassifier$Class== "Benign"),
which(trainClassifier$Class == "versicolor")),]
testClassifierLog <- testClassifier[c(which(testClassifier$Class == "Benign"),
which(testClassifier$Class == "versicolor")),]
trainClassifierLog$Class <- factor(trainClassifierLog$Class)
testClassifierLog$Class <- factor(testClassifierLog$Class)
ctrl <- trainControl(method = "repeatedcv", repeats = 15,classProbs = T,
savePredictions = T)
#create model. logistic regression is a bionomial general linear model.
#predict species based on sepal length
logisticRegression <- train(Class~ Cell.size, data = trainClassifierLog,
method = "glm", family= "binomial", trControl = ctrl)
trainClassifierLog <- trainClassifier[c(which(trainClassifier$Class== "Benign"),
which(trainClassifier$Class == "versicolor")),]
testClassifierLog <- testClassifier[c(which(testClassifier$Class == "Benign"),
which(testClassifier$Class == "versicolor")),]
trainClassifierLog$Class <- factor(trainClassifierLog$Class)
testClassifierLog$Class <- factor(testClassifierLog$Class)
ctrl <- trainControl(method = "repeatedcv", repeats = 15,classProbs = T,
savePredictions = T)
trainClassifierLog
logisticRegression <- train(Class~ Cell.size, data = trainClassifierLog,
method = "glm", family= "binomial", trControl = ctrl)
data(iris)
#split into training and test set
train_size <- floor(0.75 * nrow(iris))
set.seed(543)
train_pos <- sample(seq_len(nrow(iris)), size = train_size)
train_classifier <- iris[train_pos,]
test_classifier <- iris[-train_pos,]
dim(train_classifier)
dim(test_classifier)
#only look at two classes
train_classifier_log <- train_classifier[c(which(train_classifier$Species == "setosa"),
which(train_classifier$Species == "versicolor")),]
test_classifier_log <- test_classifier[c(which(test_classifier$Species == "setosa"),
which(test_classifier$Species == "versicolor")),]
train_classifier_log$Species <- factor(train_classifier_log$Species)
test_classifier_log$Species <- factor(test_classifier_log$Species)
ctrl <- trainControl(method = "repeatedcv", repeats = 15,classProbs = T,
savePredictions = T)
train_classifier_log
#create model. logistic regression is a bionomial general linear model.
#predict species based on sepal length
logistic_regression <- train(Species~ Sepal.Length, data = train_classifier_log,
method = "glm", family= "binomial", trControl = ctrl)
trainClassifierLog <- trainClassifier[c(which(trainClassifier$Class== "Benign"),
which(trainClassifier$Class == "Malignant")),]
testClassifierLog <- testClassifier[c(which(testClassifier$Class == "Benign"),
which(testClassifier$Class == "Malignant")),]
trainClassifierLog$Class <- factor(trainClassifierLog$Class)
testClassifierLog$Class <- factor(testClassifierLog$Class)
ctrl <- trainControl(method = "repeatedcv", repeats = 15,classProbs = T,
savePredictions = T)
trainClassifierLog
logisticRegression <- train(Class~ Cell.size, data = trainClassifierLog,
method = "glm", family= "binomial", trControl = ctrl)
trainClassifierLog <- trainClassifier[c(which(trainClassifier$Class== "benign"),
which(trainClassifier$Class == "malignant")),]
testClassifierLog <- testClassifier[c(which(testClassifier$Class == "benign"),
which(testClassifier$Class == "malignant")),]
trainClassifierLog$Class <- factor(trainClassifierLog$Class)
testClassifierLog$Class <- factor(testClassifierLog$Class)
ctrl <- trainControl(method = "repeatedcv", repeats = 15,classProbs = T,
savePredictions = T)
trainClassifierLog
logisticRegression <- train(Class~ Cell.size, data = trainClassifierLog,
method = "glm", family= "binomial", trControl = ctrl)
##ctrl <- trainControl()
## <- train(, data = , method = "", trControl = ctrl)
## predict(, newdata="")
logisticRegression
summary(logisticRegression)
##ctrl <- trainControl()
## <- train(, data = , method = "", trControl = ctrl)
## predict(, newdata="")
plot(x = roc(predictor = logisticRegression$pred$benign,
response = logisticRegression$pred$obs)$specificities,
y = roc(predictor = logisticRegression$pred$benign,
response = logistic_regression$pred$obs)$sensitivities,
col= "blue", xlim = c(1, 0), type ="l", ylab = "Sensitivity",
xlab = "Specificity")
trainClassifierLog <- trainClassifier[c(which(trainClassifier$Class== "benign"),
which(trainClassifier$Class == "malignant")),]
testClassifierLog <- testClassifier[c(which(testClassifier$Class == "benign"),
which(testClassifier$Class == "malignant")),]
trainClassifierLog$Class <- factor(trainClassifierLog$Class)
testClassifierLog$Class <- factor(testClassifierLog$Class)
ctrl1 <- trainControl(method = "repeatedcv", repeats = 15,classProbs = T,
savePredictions = T)
logisticRegression <- train(Class~ Cell.size, data = trainClassifierLog,
method = "glm", family= "binomial", trControl = ctrl1)
logisticRegression
summary(logisticRegression)
plot(x = roc(predictor = logisticRegression$pred$benign,
response = logisticRegression$pred$obs)$specificities,
y = roc(predictor = logisticRegression$pred$benign,
response = logistic_regression$pred$obs)$sensitivities,
col= "blue", xlim = c(1, 0), type ="l", ylab = "Sensitivity",
xlab = "Specificity")
plot(x = roc(predictor = logisticRegression$pred$benign,
response = logisticRegression$pred$obs)$specificities,
y = roc(predictor = logisticRegression$pred$benign,
response = logisticRegression$pred$obs)$sensitivities,
col= "blue", xlim = c(1, 0), type ="l", ylab = "Sensitivity",
xlab = "Specificity")
legend("bottomright", legend = paste("Benign v Malignant --",
roc(predictor = logisticRegression$pred$benign,
response = logisticRegression$pred$obs)$auc
, sep = ""), col = c("blue"), fill = c("blue"))
##ctrl <- trainControl()
## <- train(, data = , method = "", trControl = ctrl)
## predict(, newdata="")
logisticRegressionPredictClass <- predict(logisticRegression,
newdata = testClassifierLog)
#confusion matrix
confusionMatrix(logisticRegressionPredictClass,
reference = testClassifierLog$Class)
##ctrl <- trainControl()
## <- train(, data = , method = "", trControl = ctrl)
## predict(, newdata="")
logisticRegressionPredict <- predict(logisticRegression,
newdata = testClassifierLog, type = "prob")
# To convert from a probability to odds, divide the probability by one minus that probability. So if the probability is 10% or 0.10 , then the odds are 0.1/0.9 or ‘1 to 9’
odds_class1 <- logisticRegressionPredict[,1] / (1 - logisticRegressionPredict[,1])
log_odds_class1 <- log(odds_class1)
cor.test(log_odds_class1, testClassifierLog$Cell.size)
logisticRegressionPredict <- predict(logisticRegression,
newdata = testClassifierLog, type = "prob")
# To convert from a probability to odds, divide the probability by one minus that probability. So if the probability is 10% or 0.10 , then the odds are 0.1/0.9 or ‘1 to 9’
odds_class1 <- logisticRegressionPredict[,1] / (1 - logisticRegressionPredict[,1])
log_odds_class1 <- log(odds_class1)
cor.test(log_odds_class1, testClassifierLog$Cell.size)
logisticRegressionPredict <- predict(logisticRegression,
newdata = testClassifierLog, type = "prob")
odds_class1 <- logisticRegressionPredict[,1] / (1 - logisticRegressionPredict[,1])
log_odds_class1 <- log(odds_class1)
cor.test(log_odds_class1, testClassifierLog$Cell.size)
logisticRegressionPredictClass <- predict(logisticRegression,
newdata = testClassifierLog)
confusionMatrix(logisticRegressionPredictClass,
reference = testClassifierLog$Class)
